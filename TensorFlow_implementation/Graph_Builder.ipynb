{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Notebook, I'll write the script for training the Order-Planner Model defined in the base referenced paper\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "link to paper -> https://arxiv.org/abs/1709.00155\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "# Technology used: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as usual, I'll start with the utility cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used for processing: \n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# The tensorflow_graph_package for this implementation\n",
    "from Summary_Generator.Tensorflow_Graph.utils import *\n",
    "from Summary_Generator.Text_Preprocessing_Helpers.pickling_tools import *\n",
    "\n",
    "# import tensorflow temporarily:\n",
    "import tensorflow as tf\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "LICENSE\n",
      "Literature\n",
      "README.md\n",
      "Scripts\n",
      "TensorFlow_implementation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3) # set this seed for a device independant consistent behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "data_path = \"../Data\" # the data path\n",
    "\n",
    "data_files_paths = {\n",
    "    \"table_content\": os.path.join(data_path, \"train.box\"),\n",
    "    \"nb_sentences\" : os.path.join(data_path, \"train.nb\"),\n",
    "    \"train_sentences\": os.path.join(data_path, \"train.sent\")\n",
    "}\n",
    "\n",
    "base_model_path = \"Models\"\n",
    "plug_and_play_data_file = os.path.join(data_path, \"plug_and_play.pickle\")\n",
    "\n",
    "# constants for this script\n",
    "train_percentage = 90\n",
    "karpathy_constant = 3e-4 # for learning rate -> https://twitter.com/karpathy/status/801621764144971776?lang=en\n",
    "# I know the tweet was a joke, but I have noticed that this learning rate works quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickle the processed data file and create the train_dev pratitions for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = unPickleIt(plug_and_play_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "field_encodings = data['field_encodings']\n",
    "field_dict = data['field_dict']\n",
    "\n",
    "content_encodings = data['content_encodings']\n",
    "\n",
    "label_encodings = data['label_encodings']\n",
    "content_label_dict = data['content_union_label_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a randomized cell that prints a complete sample to verify the sanity of the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Contents: \n",
      "[('image', '<none>'), ('birthdate', '20'), ('birthdate', 'november'), ('birthdate', '1972'), ('birthplace', 'emporia'), ('birthplace', ','), ('birthplace', 'virginia'), ('position', 'defensive'), ('position', 'lineman'), ('number', '97'), ('college', 'north'), ('college', 'carolina'), ('heightft', '6'), ('heightin', '3'), ('weightlbs', '295'), ('undraftedyear', '1995'), ('stats', 'y'), ('databasefootball', 'parkerid01'), ('pfr', '<none>'), ('probowls', '<none>'), ('years', '1995\\xc2\\xa01996-2000\\xc2\\xa02001'), ('years', '2002-2003\\xc2\\xa02004'), ('teams', 'san'), ('teams', 'diego'), ('teams', 'chargers'), ('teams', 'seattle'), ('teams', 'seahawks'), ('teams', 'new'), ('teams', 'england'), ('teams', 'patriots'), ('teams', 'baltimore'), ('teams', 'ravens'), ('teams', 'san'), ('teams', 'francisco'), ('teams', '49ers'), ('articletitle', 'riddick'), ('articletitle', 'parker')]\n",
      "\n",
      "\n",
      "Summary: \n",
      "['<start>', 'riddick', 'parker', '-lrb-', 'born', 'november', '20', ',', '1972', 'in', 'emporia', ',', 'virginia', '-rrb-', 'is', 'a', 'former', 'professional', 'american', 'football', 'defensive', 'lineman', 'for', 'the', 'seattle', 'seahawks', ',', 'san', 'diego', 'chargers', ',', 'new', 'england', 'patriots', ',', 'baltimore', 'ravens', ',', 'and', 'san', 'francisco', '49ers', 'of', 'the', 'national', 'football', 'league', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(field_encodings)\n",
    "\n",
    "random_index = np.random.randint(total_samples)\n",
    "\n",
    "# extract the three parts of this random sample\n",
    "random_field_sample = field_encodings[random_index]\n",
    "content_sample = content_encodings[random_index]\n",
    "label_sample = label_encodings[random_index]\n",
    "\n",
    "# print the extracted sample in meaningful format\n",
    "print(\"Table Contents: \")\n",
    "print([(field_dict[field], content_label_dict[content]) \n",
    "       for (field, content) in zip(random_field_sample, content_sample)])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Summary: \")\n",
    "print([content_label_dict[label] for label in label_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the above cell multiple times to satisfy yourself that the data is still sane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform random shuffling of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = synch_random_shuffle_non_np(zip(field_encodings, content_encodings), label_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform train_dev_splitting of the given data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_Y, dev_X, dev_Y = split_train_dev(X, Y, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of Examples in Training set: ', 9)\n",
      "('Number of Examples in the dev  set: ', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Examples in Training set: \", len(train_X))\n",
    "print(\"Number of Examples in the dev  set: \", len(dev_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building graph here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the built graph will be later added to the code package Summary_Generator. This is being done here since the graph building process becomes quite easy with jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 0: Set the Hyper constants for the graph building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some hyper constants to be used in the graph building:\n",
    "\n",
    "# random_seed value for consistent debuggable behaviour\n",
    "seed_value = 3\n",
    "\n",
    "# vocabulary sizes\n",
    "field_vocab_size = data['field_vocab_size']\n",
    "content_label_vocab_size = data['content_label_vocab_size']\n",
    "\n",
    "# Embeddings size:\n",
    "field_embedding_size = 100\n",
    "content_label_embedding_size = 400 # This is a much bigger vocabulary compared to the field_name's vocabulary\n",
    "\n",
    "# LSTM hidden state sizes\n",
    "lstm_cell_state_size = hidden_state_size = 500 # they are same (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graph reset point:\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1: Create placeholders for the computations in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for the input data:\n",
    "with tf.variable_scope(\"Input_Data\"):\n",
    "    tf_field_encodings = tf.placeholder(tf.int32, shape=(None, None), name=\"input_field_encodings\")\n",
    "    tf_content_encodings = tf.placeholder(tf.int32, shape=(None, None), name=\"input_content_encodings\")\n",
    "    tf_label_encodings = tf.placeholder(tf.int32, shape=(None, None), name=\"input_label_encodings\")\n",
    "    \n",
    "    # This is a placeholder for storing the lengths of the input sequences (they are padded to tensor)\n",
    "    tf_input_seqs_lengths = tf.placeholder(tf.int32, shape=(None,), name=\"input_sequence_lengths\")\n",
    "    \n",
    "    # This is a placeholder for storing the lengths of the decoder sequences (they are padded to tensor)\n",
    "    tf_label_seqs_lengths = tf.placeholder(tf.int32, shape=(None,), name=\"decoder_sequence_lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the one-hot encoded values for the label_encodings\n",
    "with tf.variable_scope(\"One_hot_encoder\"):\n",
    "    tf_one_hot_label_encodings = tf.one_hot(tf_label_encodings, depth=content_label_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Input_Data/input_field_encodings:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# check tf_field_encodings\n",
    "print(tf_field_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: Obtain Embeddings for the input and the output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scope for the shared Content_Label matrix\n",
    "with tf.variable_scope(\"Unified_Vocabulary_Matrix\"):\n",
    "    content_label_embedding_matrix = tf.get_variable(\"content_label_embedding_matrix\", \n",
    "                                shape=(content_label_vocab_size, content_label_embedding_size), \n",
    "                                initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                                dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embeddings for the given input data:\n",
    "with tf.variable_scope(\"Input_Embedder\"):\n",
    "    # Embed the field encodings:\n",
    "    field_embedding_matrix = tf.get_variable(\"field_embedding_matrix\", \n",
    "                                shape=(field_vocab_size, field_embedding_size), \n",
    "                                initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                                dtype=tf.float32)\n",
    "    \n",
    "    tf_field_embedded = tf.nn.embedding_lookup(field_embedding_matrix, tf_field_encodings, name=\"field_embedder\")\n",
    "    \n",
    "    # Embed the content encodings: \n",
    "    \n",
    "    \n",
    "    tf_content_embedded = tf.nn.embedding_lookup(content_label_embedding_matrix, \n",
    "                                                 tf_content_encodings, name=\"content_embedder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Embedded_Input_Tensors: ', <tf.Tensor 'Input_Embedder/field_embedder:0' shape=(?, ?, 100) dtype=float32>, <tf.Tensor 'Input_Embedder/content_embedder:0' shape=(?, ?, 400) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedded_Input_Tensors: \", tf_field_embedded, tf_content_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embeddings for the label (summary sentences):\n",
    "with tf.variable_scope(\"Label_Embedder\"):\n",
    "    # embed the label encodings\n",
    "    tf_label_embedded = tf.nn.embedding_lookup(content_label_embedding_matrix, \n",
    "                                                 tf_label_encodings, name=\"label_embedder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Embedded_Label_Tensors: ', <tf.Tensor 'Label_Embedder/label_embedder:0' shape=(?, ?, 400) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedded_Label_Tensors: \", tf_label_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the Input embeddings channel_wise and obtain the combined input tensor\n",
    "with tf.variable_scope(\"Input_Concatenator\"):\n",
    "    tf_field_content_embedded = tf.concat([tf_field_embedded, tf_content_embedded], axis=-1, name=\"concatenator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Final_Input_to_the_Encoder: ', <tf.Tensor 'Input_Concatenator/concatenator:0' shape=(?, ?, 500) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final_Input_to_the_Encoder: \", tf_field_content_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3: Create the encoder RNN to obtain the encoded input sequences. <b>(The Encoder Module)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Encoder\"):\n",
    "    encoded_input, encoder_final_state = tf.nn.dynamic_rnn (\n",
    "                            cell = tf.nn.rnn_cell.LSTMCell(lstm_cell_state_size), # let all parameters to be default\n",
    "                            inputs = tf_field_content_embedded,\n",
    "                            sequence_length = tf_input_seqs_lengths,\n",
    "                            dtype = tf.float32\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Encoded_vectors_bank for attention mechanism: ', <tf.Tensor 'Encoder/rnn/transpose:0' shape=(?, ?, 500) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded_vectors_bank for attention mechanism: \", encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# define the size parameter for the encoded_inputs\n",
    "encoded_inputs_embeddings_size = encoded_input.shape[-1]\n",
    "print encoded_inputs_embeddings_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Final_state obtained from the last step of encoder: ', LSTMStateTuple(c=<tf.Tensor 'Encoder/rnn/while/Exit_2:0' shape=(?, 500) dtype=float32>, h=<tf.Tensor 'Encoder/rnn/while/Exit_3:0' shape=(?, 500) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "print(\"Final_state obtained from the last step of encoder: \", encoder_final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4: define the Attention Mechanism for the Model <b>(The Dispatcher Module)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4.1: define the content based attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Content_Based_Attention/trainable_weights\"):\n",
    "    '''\n",
    "        These weights and bias matrices must be compatible with the dimensions of the h_values and the f_values\n",
    "        passed to the function below. If they are not, some exception might get thrown and it would be difficult\n",
    "        to debug it. \n",
    "    '''\n",
    "    # field weights for the content_based attention\n",
    "    W_f = tf.get_variable(\"field_attention_weights\", shape=(field_embedding_size, content_label_embedding_size),\n",
    "                         initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value))\n",
    "    b_f = tf.get_variable(\"field_attention_biases\", shape=(field_embedding_size, 1),\n",
    "                         initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value))\n",
    "    \n",
    "    # hidden states weights for the content_based attention\n",
    "    W_c = tf.get_variable(\"content_attention_weights\", \n",
    "                          shape=(encoded_inputs_embeddings_size, content_label_embedding_size),\n",
    "                          initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value))\n",
    "    b_c = tf.get_variable(\"content_attention_biases\", shape=(encoded_inputs_embeddings_size, 1),\n",
    "                          initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Content_Based_Attention\"):\n",
    "    def get_content_based_attention_vectors(query_vectors):\n",
    "        '''\n",
    "            function that returns the alpha_content vector using the yt-1 (query vectors)\n",
    "        '''\n",
    "        # use the W_f and b_f to transform the query_vectors to the shape of f_values\n",
    "        f_trans_query_vectors = tf.matmul(W_f, tf.transpose(query_vectors)) + b_f\n",
    "        # use the W_c and b_c to transform the query_vectors to the shape of h_values\n",
    "        h_trans_query_vectors = tf.matmul(W_c, tf.transpose(query_vectors)) + b_c\n",
    "        \n",
    "        # // TODO: calculate the field_attention_values and the hidden_attention_values\n",
    "        print f_trans_query_vectors.shape, tf_field_embedded.shape\n",
    "        \n",
    "        # create a zip of the required values:\n",
    "        print zipper\n",
    "        \n",
    "        \n",
    "        field_attention_values = field_attention_values.stack()[:, :, 0] # drop the last dimension (1 sized)\n",
    "        hidden_attention_values = hidden_attention_values.stack()[:, :, 0] # same for this one\n",
    "        \n",
    "        # return the element wise multiplied values followed by softmax\n",
    "        return tf.nn.softmax(field_attention_values * hidden_attention_values, name=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, ?) (?, ?, 100)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b44039e7fe8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_content_based_attention_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-9ab493115bdf>\u001b[0m in \u001b[0;36mget_content_based_attention_vectors\u001b[0;34m(query_vectors)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mf_trans_query_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_field_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# create a zip of the required values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mzipper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_trans_query_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_field_embedded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mzipper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0minvoked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \"\"\"\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'Tensor' object is not iterable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not iterable."
     ]
    }
   ],
   "source": [
    "get_content_based_attention_vectors(tf.placeholder(tf.float32, shape=(None, None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4.2: define the link based attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Link_Based_Attention/trainable_weights\"):\n",
    "    '''\n",
    "        The dimensions of the Link_Matrix must be properly compatible with the field_vocab_size.\n",
    "        If they are not, some exception might get thrown and it would be difficult\n",
    "        to debug it.\n",
    "    '''\n",
    "    Link_Matrix = tf.get_variable(\"Link_Attention_Matrix\", shape=(field_vocab_size, field_vocab_size),\n",
    "            dtype=tf.float32, initializer=tf.truncated_normal_initializer(mean=0.5, stddev=0.5, seed=seed_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Link_Based_Attention/trainable_weights/Link_Attention_Matrix:0' shape=(106, 106) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(Link_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function for obtaining the link based attention values.\n",
    "with tf.variable_scope(\"Link_Based_Attention\"):\n",
    "    def get_link_based_attention_vectors(prev_attention_vectors):\n",
    "        '''\n",
    "            This function generates the link based attention vectors using the Link matrix and the \n",
    "        '''\n",
    "        # carve out only the relevant values from the Link matrix\n",
    "        \n",
    "        \n",
    "        matrix_all_values_from = tf.nn.embedding_lookup(Link_Matrix, tf_field_encodings)\n",
    "        pretemp = tf.transpose(matrix_all_values_from, perm=[0, 2, 1])\n",
    "        \n",
    "        _, vals = tf.while_loop(\n",
    "            lambda i, x: tf.less(i, x.size()),\n",
    "            lambda i, x: (tf.add(i, 1), x.write(i, tf.gather(pretemp[i, :, :], tf_field_encodings[i, :]))),\n",
    "            [tf.constant(0), tf.TensorArray(tf.float32, size=prev_attention_vectors.shape[0])]\n",
    "        )\n",
    "        \n",
    "        matrix_relevant_values = tf.transpose(\n",
    "                        vals.stack(), \n",
    "                        perm=[0, 2, 1])\n",
    "        \n",
    "        return tf.nn.softmax(tf.reduce_sum(prev_attention_vectors * matrix_relevant_values, axis=1),name=\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4.3: define the hybrid attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the hybrid of the content based and the link based attention\n",
    "with tf.variable_scope(\"Hybrid_attention/trainable_weights\"):\n",
    "    # for now, this is just the content_based attention:\n",
    "    Zt_weights = tf.get_variable(\"zt_gate_parameter_vector\", dtype=tf.float32,\n",
    "                                 initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                                 shape=(hidden_state_size + field_embedding_size + content_label_embedding_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Hybrid_attention\"):\n",
    "    # define the hybrid_attention_calculator function:\n",
    "    def get_hybrid_attention(h_values, y_values, content_attention, link_attention):\n",
    "        '''\n",
    "            function to calcuate the hybrid attention using the content_attention and the link_attention\n",
    "        '''\n",
    "        # calculate the e_f values\n",
    "        e_t = tf.reduce_sum(link_attention * tf_field_embedded, axis=1)\n",
    "        \n",
    "        # create the concatenated vectors from h_values e_t and y_values\n",
    "        input_to_zt_gate = tf.concat([h_values, e_t, y_values], axis=-1) # channel wise concatenation\n",
    "        \n",
    "        # perfrom the computations of the z gate:\n",
    "        z_t = tf.nn.sigmoid(tf.matmul(input_to_zt_gate, Zt_weights))\n",
    "        \n",
    "        # calculate z_t~ value using the empirical values = 0.2z_t + 0.5\n",
    "        z_t_tilde = (0.2 * z_t) + 0.5\n",
    "        \n",
    "        # compute the final hybrid_attention_values using the z_t_tilde values over content and link based values\n",
    "        hybrid_attention = (z_t_tilde * content_attention) + ((1 - z_t_tilde) * link_attention)\n",
    "        \n",
    "        # return the calculated hybrid attention:\n",
    "        return hybrid_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5: create the decoder RNN to obtain the generated summary for the structured data <b>(The Decoder Module)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " with tf.variable_scope(\"Decoder/trainable_weights\"):\n",
    "        # define the weights for the output projection calculation\n",
    "        W_output = tf.get_variable(\n",
    "                            \"output_projector_matrix\", dtype=tf.float32,\n",
    "                            initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                            shape=(hidden_state_size, content_label_vocab_size))\n",
    "        b_output = tf.get_variable(\n",
    "                            \"output_projector_biases\", dtype=tf.float32,\n",
    "                            initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                            shape=(content_label_vocab_size,))\n",
    "        \n",
    "        # define the weights and biases for the x_t calculation\n",
    "        W_d = tf.get_variable(\n",
    "                        \"x_t_gate_matrix\", dtype=tf.float32,\n",
    "                        initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                        shape=((hidden_state_size + content_label_embedding_size), content_label_embedding_size))\n",
    "        b_d = tf.get_variable(\n",
    "                            \"x_t_gate_biases\", dtype=tf.float32,\n",
    "                            initializer=tf.random_uniform_initializer(minval=-1, maxval=1, seed=seed_value),\n",
    "                            shape=(content_label_embedding_size,))\n",
    "        \n",
    "        # create the LSTM cell to be used for decoding purposes\n",
    "        decoder_cell = tf.nn.rnn_cell.LSTMCell(lstm_cell_state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(start_tokens, mode = \"inference\", decoder_lengths = None, w_reuse = True):\n",
    "    '''\n",
    "        Function that defines the decoder op and returns the decoded sequence (the summary)\n",
    "        \n",
    "        @params:\n",
    "        start_tokens = a tensor containing the start tokens (one for each sequence in the batch)\n",
    "        mode = a value from \"training\" or \"inference\" to determine for how long the decoder rnn is to be unrolled.\n",
    "               behaviour is as follows:\n",
    "               \"training\" => The rnn will be unrolled until the max(decode_lengths). decode_lengths cannot be None.\n",
    "               \"inference\" => decode_lengths is be ignored and unrolling will be done till <eos> is received\n",
    "               \n",
    "    '''\n",
    "    with tf.variable_scope(\"Decoder\", reuse = w_reuse):\n",
    "        # define the function to obtain the predictions out of the given hidden_state_values\n",
    "        def get_predictions(h_t_values):\n",
    "            '''\n",
    "                This function transforms the h_t_values into a one_hot_type probability vector\n",
    "            '''\n",
    "            # apply the output_projection gate to obtain the predictions from the h_t_values\n",
    "            predictions = tf.matmul(h_t_values, W_output) + b_output\n",
    "            \n",
    "            # return the predictions:\n",
    "            return predictions\n",
    "        \n",
    "        \n",
    "        # define a function to obtain the values for the next input to the LSTM_cell (y_t values)\n",
    "        def get_y_t_values(pred_vals):\n",
    "            '''\n",
    "                pred_vals = the tensor of shape [batch_size x content_label_vocab_size]\n",
    "            '''\n",
    "            \n",
    "            # calculate the next words to be predicted \n",
    "            act_preds = tf.argmax(pred_vals, axis=-1)\n",
    "            \n",
    "            # perform embedding lookup for these act_preds\n",
    "            y_t_values = tf.nn.embedding_lookup(content_label_embedding_matrix, act_preds)\n",
    "            \n",
    "            # return the calculated y_t_values\n",
    "            return y_t_values\n",
    "            \n",
    "        \n",
    "        # write the loop function for the raw_rnn:\n",
    "        def decoder_loop_function(time, cell_output, cell_state, loop_state):\n",
    "            '''\n",
    "                The decoder loop function for the raw_rnn\n",
    "                (In future will implement the attention mechanism using the loop_state parameter.)\n",
    "                @params\n",
    "                compatible with -> https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn\n",
    "            '''\n",
    "            if(cell_state is None):\n",
    "                # initial call of the loop function\n",
    "                finished = (time >= tf_label_seqs_lengths)\n",
    "                next_input = start_tokens\n",
    "                next_cell_state = encoder_final_state\n",
    "                emit_output = tf.zeros(shape=(tf_field_encodings.shape[0], content_label_vocab_size), dtype=tf.float32)\n",
    "                next_loop_state = tf.zeros_like(tf_field_encodings, dtype=tf.float32)\n",
    "                \n",
    "            else:\n",
    "                # we define the loop_state as the prev_hybrid attention_vector!\n",
    "                prev_attention_vectors = loop_state # extract the prev_attention_vector from the loop state\n",
    "                \n",
    "                # obtain the predictions for the cell_output\n",
    "                preds = get_predictions(cell_output)\n",
    "                \n",
    "                # obtain the y_t_values from the cell_output values:\n",
    "                y_t_values = get_y_t_values(preds)\n",
    "                \n",
    "                ''' Calculate the attention: '''\n",
    "                # calculate the content_based attention values using the defined module\n",
    "                cont_attn = get_content_based_attention_vectors(y_t_values)\n",
    "                print \"y_t_values: \", y_t_values\n",
    "                \n",
    "                # calculate the link based attention values\n",
    "                link_attn = get_link_based_attention_vectors(prev_attention_vectors)\n",
    "                print link_attn\n",
    "                \n",
    "                # calculate the hybrid_attention\n",
    "                hybrid_attn = get_hybrid_attention(cell_output, y_t_values, cont_attn, link_attn)\n",
    "                \n",
    "                ''' Calculate the x_t vector for next_input value'''\n",
    "                # use the hybrid_attn to attend over the encoded_input (to calculate the a_t values)\n",
    "                a_t_values = tf.reduce_sum(hybrid_attn * encoded_input, axis=1) \n",
    "                \n",
    "                # apply the x_t gate\n",
    "                x_t = tf.tanh(tf.matmul(tf.concat([a_t_values, y_t_values], axis=-1), W_d) + b_d)\n",
    "                \n",
    "                \n",
    "                ''' Calculate the finished vector for perfoming computations '''\n",
    "                # for now it is just the decoder length completed or not value.\n",
    "                finished = (time >= decoder_lengths)\n",
    "                \n",
    "                ''' Copy mechanism is left (//TODO: change the following and implement copy mechanism)'''\n",
    "                emit_output = preds\n",
    "                \n",
    "                # The next_input is the x_t vector so calculated:\n",
    "                next_input = x_t\n",
    "                # The next loop_state is the current hybrid_attention vectors\n",
    "                next_loop_state = hybrid_attn\n",
    "                # The next_cell_state is going to be equal to the cell_state. (we_don't tweak it)\n",
    "                next_cell_state = cell_state\n",
    "            \n",
    "            # In both the cases, the return value is same.\n",
    "            # return all these created parameters\n",
    "            return (finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "        \n",
    "        # use the tf.nn.raw_rnn to define the decoder computations\n",
    "        outputs, _, _ = tf.nn.raw_rnn(decoder_cell, decoder_loop_function)\n",
    "        \n",
    "    # return the outputs obtained from the raw_rnn:\n",
    "    return outputs.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "step 6: define the training computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape to a Tensor: (?, 421)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7fa14c40c99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training_computations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     outputs = decode(tf_label_embedded[:, 0, :], mode=\"training\", \n\u001b[0;32m----> 3\u001b[0;31m                      decoder_lengths=tf_label_seqs_lengths, w_reuse=None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-fa71729ef267>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(start_tokens, mode, decoder_lengths, w_reuse)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# use the tf.nn.raw_rnn to define the decoder computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_loop_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# return the outputs obtained from the raw_rnn:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36mraw_rnn\u001b[0;34m(cell, loop_fn, parallel_iterations, swap_memory, scope)\u001b[0m\n\u001b[1;32m    974\u001b[0m     (elements_finished, next_input, initial_state, emit_structure,\n\u001b[1;32m    975\u001b[0m      \u001b[0minit_loop_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m          time, None, None, None)  # time, cell_output, cell_state, loop_state\n\u001b[0m\u001b[1;32m    977\u001b[0m     \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-fa71729ef267>\u001b[0m in \u001b[0;36mdecoder_loop_function\u001b[0;34m(time, cell_output, cell_state, loop_state)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mnext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mnext_cell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_final_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0memit_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_field_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_label_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mnext_loop_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_field_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[0;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     raise ValueError(\n\u001b[0;32m--> 250\u001b[0;31m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0m\u001b[1;32m    251\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0mint64_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (?, 421)"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"Training_computations\"):\n",
    "    outputs = decode(tf_label_embedded[:, 0, :], mode=\"training\", \n",
    "                     decoder_lengths=tf_label_seqs_lengths, w_reuse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the outputs:\n",
    "print(\"Output_tensor: \", outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "step 7: define the cost function and the optimizer to perform the optimization on this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the loss (objective) function for minimization\n",
    "with tf.variable_scope(\"Loss\"):\n",
    "    log_product = tf_one_hot_label_encodings * tf.log(outputs)\n",
    "    loss = - tf.reduce_mean(log_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the optimizer for this task:\n",
    "with tf.variable_scope(\"Trainer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=karpathy_constant)\n",
    "    # define the train_step for this:\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step _ : define the errands for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Errands\"): \n",
    "    init = tf.global_variables_initializer()\n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a stub_session to generate the graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Model_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(base_model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tensorboard_writer = tf.summary.FileWriter(model_path, graph=sess.graph, filename_suffix=\".bot\")\n",
    "    \n",
    "    # initialize the session to generate the visualization file\n",
    "    sess.run(init)\n",
    "    \n",
    "    tvars = tf.trainable_variables()\n",
    "    tvars_vals = sess.run(tvars)\n",
    "    \n",
    "    for var, val in zip(tvars, tvars_vals):\n",
    "        print(var.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the session runner to check if the training loops execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell ensures that although there are no errors in the graph compilation, the runtime execution of the model also doesn't cause any problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The following is just a runtime checker session loop. This loop is not the training loop for the model.\n",
    "Which is the reason why, the model is not saved upon executing'''\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # run the initializer to create the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # obtain the padded training data:\n",
    "    inp_field = pad_sequences(field_encodings)\n",
    "    inp_conte = pad_sequences(content_encodings)\n",
    "    inp_label = pad_sequences(label_encodings)\n",
    "    # print inp_field.shape, inp_conte.shape, inp_label.shape\n",
    "    \n",
    "    # obtain the sequence lengths for the field_encodings and the label_encodings\n",
    "    inp_lengths = get_lengths(field_encodings)\n",
    "    lab_lengths = get_lengths(label_encodings)\n",
    "    # print inp_lengths, lab_lengths\n",
    "    \n",
    "    # run a loop for 20 iterations:\n",
    "    for epoch in range(20):\n",
    "        print \"current_epoch: \", (epoch + 1)\n",
    "        # execute the cost and the train_step\n",
    "        mem_back, _, cost = sess.run([encoded_input, train_step, loss], feed_dict={\n",
    "            tf_field_encodings: inp_field,\n",
    "            tf_content_encodings: inp_conte,\n",
    "            tf_label_encodings: inp_label,\n",
    "            tf_input_seqs_lengths: inp_lengths,\n",
    "            tf_label_seqs_lengths: lab_lengths\n",
    "        })\n",
    "        print mem_back\n",
    "        print \"Cost: \", cost, \"\\n\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
