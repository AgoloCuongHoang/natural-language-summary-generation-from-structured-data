{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Notebook, I'll write the script for training the Order-Planner Model defined in the base referenced paper\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "link to paper -> https://arxiv.org/abs/1709.00155\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "# Technology used: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as usual, I'll start with the utility cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used for processing: \n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# The tensorflow_graph_package for this implementation\n",
    "from Summary_Generator.Tensorflow_Graph.utils import *\n",
    "from Summary_Generator.Text_Preprocessing_Helpers.pickling_tools import *\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "LICENSE\n",
      "Literature\n",
      "README.md\n",
      "Scripts\n",
      "TensorFlow_implementation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3) # set this seed for a device independant consistent behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "data_path = \"../Data\" # the data path\n",
    "\n",
    "data_files_paths = {\n",
    "    \"table_content\": os.path.join(data_path, \"train.box\"),\n",
    "    \"nb_sentences\" : os.path.join(data_path, \"train.nb\"),\n",
    "    \"train_sentences\": os.path.join(data_path, \"train.sent\")\n",
    "}\n",
    "\n",
    "base_model_path = \"Models\"\n",
    "plug_and_play_data_file = os.path.join(data_path, \"plug_and_play.pickle\")\n",
    "\n",
    "# constants for the preprocessing script\n",
    "train_percentage = 95 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickle the processed data file and create the train_dev pratitions for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unPickleIt(plug_and_play_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_encodings = data['field_encodings']\n",
    "field_dict = data['field_dict']\n",
    "\n",
    "content_encodings = data['content_encodings']\n",
    "content_dict = data['content_dict']\n",
    "\n",
    "label_encodings = data['label_encodings']\n",
    "label_dict = data['label_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a randomized cell that prints a complete sample to verify the sanity of the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Contents: \n",
      "[('image', 'jim'), ('image', 'bob'), ('image', 'at'), ('image', 'relentless'), ('image', 'garage.jpg'), ('caption', 'jim'), ('caption', 'bob'), ('caption', 'performing'), ('caption', 'at'), ('caption', 'the'), ('caption', 'garage'), ('caption', ','), ('caption', '2010'), ('name', 'jim'), ('name', 'bob'), ('imagesize', '<none>'), ('background', 'solo_singer'), ('birthdate', '22'), ('birthdate', 'november'), ('birthdate', '1960'), ('origin', 'london'), ('origin', ','), ('origin', 'england'), ('genre', 'punk'), ('genre', 'rock'), ('genre', ','), ('genre', 'acoustic'), ('yearsactive', '1985'), ('yearsactive', '--'), ('label', 'the'), ('label', 'ten'), ('label', 'forty'), ('label', 'sound'), ('label', 'cherry'), ('label', 'red'), ('label', 'emi'), ('label', 'big'), ('label', 'cat'), ('label', 'rough'), ('label', 'trade'), ('label', 'fierce'), ('label', 'panda'), ('associatedacts', 'carter'), ('associatedacts', 'usm'), ('associatedacts', 'jim'), ('associatedacts', \"'s\"), ('associatedacts', 'super'), ('associatedacts', 'stereoworld'), ('associatedacts', 'james'), ('associatedacts', 'robert'), ('associatedacts', 'morrison'), ('associatedacts', 'abdoujaparov'), ('associatedacts', 'idou'), ('associatedacts', 'chris'), ('associatedacts', 't-t'), ('articletitle', 'jim'), ('articletitle', 'bob')]\n",
      "\n",
      "\n",
      "Summary: \n",
      "['<start>', 'jim', 'bob', '-lrb-', 'born', 'james', 'neil', 'morrison', 'on', '22', 'november', '1960', '-rrb-', 'is', 'a', 'british', 'musician', 'and', 'author', ',', 'best', 'known', 'as', 'the', 'singer', 'of', 'indie', 'punk', 'band', 'carter', 'usm', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(field_encodings)\n",
    "\n",
    "random_index = np.random.randint(total_samples)\n",
    "\n",
    "# extract the three parts of this random sample\n",
    "random_field_sample = field_encodings[random_index]\n",
    "content_sample = content_encodings[random_index]\n",
    "label_sample = label_encodings[random_index]\n",
    "\n",
    "# print the extracted sample in meaningful format\n",
    "print(\"Table Contents: \")\n",
    "print([(field_dict[field], content_dict[content]) for (field, content) in zip(random_field_sample, content_sample)])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Summary: \")\n",
    "print([label_dict[label] for label in label_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the above cell multiple times to satisfy yourself that the data is still sane."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
